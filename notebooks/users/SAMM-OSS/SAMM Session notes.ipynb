{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OWASP SAMM Session notes\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/OWASP/samm/master/Supporting%20Resources/v2.0/LOGO-SAMM.png\" width=200/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAMM user session - Introduction\n",
    "\n",
    "4 users in the room, 2 remote participants\n",
    "\n",
    "### Expectations for the week\n",
    "- Assessment checklist\n",
    "- Assessment toolkit\n",
    "- Roadmap\n",
    "- BSIMM/SAMM\n",
    "- Improve feedback loop\n",
    "- Measurement\n",
    "- Guidance documents for different contexts (Agile, DevOps, Waterfall, even for business vs development)\n",
    "\n",
    "### Discussion\n",
    "- Map to other tools, maybe OWASP tools, where you can use other tools for a certain practice, concrete vs. technology agnostic\n",
    "- Map activities to OWASP projects\n",
    "- SAMM as an umbrella project for other OWASP projects\n",
    "- Have projects categorize themselves inside SAMM\n",
    "- Have sample use cases\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAMM - Measurement model\n",
    "\n",
    "## Bart's presentation\n",
    "\n",
    "Where are we?\n",
    "- coverage\n",
    "- quality\n",
    "\n",
    "Goals\n",
    "\n",
    "There isn't a model that fits all\n",
    "Benchmarking. Use categories for sectors?\n",
    "\n",
    "Address metrics. Maybe map the questions to metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAMM - Measurement model (Mon EV)\n",
    "\n",
    "## Questions\n",
    "\n",
    "#### Goals\n",
    "- Well written\n",
    "- Enable self-assessment\n",
    "\n",
    "### Options\n",
    "\n",
    "### Create question + guidance\n",
    "Get together in groups to work on question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DevOps (Wed PM)\n",
    "\n",
    "### Mapping to SAMM\n",
    "\n",
    "inventory of applications appears nowhere in the model. \n",
    "maybe it should be in the quality criteria for some question. secure deployment or environment management.\n",
    "\n",
    "back up before deployment\n",
    "\n",
    "secure deployment (guidelines?)  \n",
    "risk: while a deployment is performed, the application cannot be reached.  \n",
    "opportunity: deployment without downtime is performed\n",
    "\n",
    "risk: by using environment dependent configuration, some parameters will not be tested correctly\n",
    "opportunity: usage of environment independent configuration parameter, called feature toggles, helps enhance test coverage\n",
    "\n",
    "NEXT STEP: Create a spreadsheet to map activities from both models and see if there are holes in it\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evening session\n",
    "\n",
    "\n",
    "### GitHub issues\n",
    "\n",
    "#### Restructure Secure Deployment Stream A\n",
    "#123 \n",
    "\n",
    "secure build - points for integrating security testing tools into the build pipeline\n",
    "secure deploy -  points for \n",
    "security testing - are you doing it well even as a stand-alone practice? SAST or DAST well\n",
    "\n",
    "build is where you decide how you're going to record the integrity of what you're building\n",
    "deploy is where you verify\n",
    "\n",
    "#### Revise integrity checks in secure build and deployment\n",
    "#124\n",
    "\n",
    "From GitHub  \n",
    "Build\t\t\t\t            Deployment\n",
    "1. hash or code sign |\t        -\n",
    "2. code sign for ext only |    Verify integrity\n",
    "3. code sign ext and int |\t    Verify signature\n",
    "\n",
    "Chris  \n",
    "level 1 - store your artifacts somewhere safe where it can't be modified\n",
    "\n",
    "Internal vs. external discussion\n",
    "\n",
    "Bart doesn't agree because it implies we should check for external first and it might not apply to every company.  \n",
    "Seba says including internal and external it messes up with the scope. It could be more interesting to talk about you \"trust levels\", \"trust zone\", or \"span of control\". It makes more sense.\n",
    "\n",
    "\n",
    "Bart's suggestion  \n",
    "1. evidence of integrity, like a hash\n",
    "2. integrity is not tamperable, protected evidence, not easy to change, like a signature\n",
    "3. deterministic build (can everyone do it?) create a strong link between the source code and the binary. it keeps your integrity over the build process.\n",
    "\n",
    "**Conclusion**\n",
    "\n",
    "Change build to:  \n",
    "1. E.g., Hash\n",
    "2. E.g., Code sign - proof is hard-linked to artifact - and auth'd\n",
    "3. Deterministic - build process itself has integrity (reproducible build)\n",
    "\n",
    "Keep deployment as it is, not requiring integrity verification.\n",
    "2. Verify integrity\n",
    "3. Verify signature\n",
    "\n",
    "For both, use terms that are terminology-agnostic.\n",
    "\n",
    "Hashing and code signing should be examples - describe their properties (e.g. hard linked to artifact)\n",
    "\n",
    "\n",
    "### References\n",
    "\n",
    "\n",
    "#### OWASP references\n",
    "\n",
    "Only reference Lab or Flaghsip projects\n",
    "\n",
    "Add more details when using OWASP references.\n",
    "\n",
    "They are part of the Additional documents, not the core model.\n",
    "\n",
    "Add more details  \n",
    "- name of the project\n",
    "- version\n",
    "- some other info that makes sense in the project\n",
    "\n",
    "#### External references\n",
    "\n",
    "It could be a link to the DevSecOps maturity model.\n",
    "\n",
    "Be careful what you include because they imply endorsement.\n",
    "\n",
    "Be explicit about this: external references don't mean SAMM endorse them.\n",
    "\n",
    "They are part of the Additional documents, not the core model.\n",
    "\n",
    "#### SAMM references\n",
    "\n",
    "Add internal references in the core model.\n",
    "\n",
    "Include  \n",
    "- Business\n",
    "- function\n",
    "- practice\n",
    "- stream\n",
    "- level\n",
    "\n",
    "Dependencies between business functions and streams\n",
    "\n",
    "### Contributing to the SAMM project\n",
    "\n",
    "Jan created a guidance document.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grammar\n",
    "- Use the active voice\n",
    "- Examples:  \n",
    "  You do this  \n",
    "  You have this\n",
    "\n",
    "Vocabulary\n",
    "- Be consistent throughout the model  \n",
    "  E.g., \"Artifact x\" is stored in an accessible location\n",
    "- Be specific\n",
    "  Don’t: You have fully documented build processes  \n",
    "  Do: You have enough information to recreate the build\n",
    "\n",
    "Scope\n",
    "- If something applies to all questions, say it once at the beginning\n",
    "- E.g., the questions apply to all the applications in scope\n",
    "\n",
    "Quality criteria\n",
    "- It helps with the roadmap  \n",
    "  So you can decide what to do if you don’t meet a particular quality check\n",
    "- It's aligned with and supports the benefit of the activity\n",
    "\n",
    "Internal references\n",
    "- Don’t include references to other stream activities in the questions. \n",
    "- Be specific in the question, use the same concepts and similar wording, and have the reference in the prose.\n",
    "- Maybe add a section in the markdown for internal references.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Threat Modeling\n",
    "\n",
    "Feedback  \n",
    "Gaps between maturity levels seem too big, too hard (by adding the quality variable)  \n",
    "Extend the scale  \n",
    "how well, how widely (adoption) do you do it?\n",
    "\n",
    "threat modeling group\n",
    "\n",
    "#### Level 1\n",
    "ad hoc thread models, free form  \n",
    "\n",
    "- you're just doing something. anyway is good enough.\n",
    "- you're looking at either threats against people and processes or technical things (because some companies start with tools). If you do both, are you still at level 1?\n",
    "- minimum requirement: it's noted down somewhere, captured. evidence.\n",
    "- you're doing it at regular intervals, you maintain it\n",
    "- who does it? anybody\n",
    "  \n",
    "-\n",
    "  \n",
    "#### Level 2\n",
    "implement a thred model methodology + classification of systems and levels of TM depth / accurate documentation that reflects reality / ownership is withing the security/architecture team\n",
    "\n",
    "- methodology and related to app classification. \n",
    "- if different teams look for threats, they should find the same critical and high level threats.\n",
    "- repeatability of the process. maybe not for outputs? will it be too hard for companies to achieve this level?\n",
    "- write down what your methodology is  \n",
    "- you don't need to do it for all your applications, but if you\n",
    "- you need a specification of your system (user stories or other)\n",
    "- who does it? at this point, architecture or security team. someone with knowledge. not embeded in your development process. you probably need a group of people (someone who knows the system, a threat modeler, someone who knows the business)\n",
    "- it's more formal in terms of stakeholders involved.\n",
    "- how important is the project? define depth of threat level. \n",
    "- classify systems - quantify risk of applications\n",
    "- how detailed is your threat model for this application?\n",
    "- Something like ASVS\n",
    "- defined methodology and shared knowledge\n",
    "- alignment between classification of applications and the level of threat modeling for those applications\n",
    "- ownership of the process\n",
    "- Steve said this, there was some discussion for and against it E.g., Agile mvp, add mvs (minimum viable security)\n",
    "    \n",
    "#### Level 3\n",
    "Threat modeling process is integrated in the SDLC (and ownership moves to development teams) / repeatability / digitization and linkability / libraries (e.g., attack trees / threat libraries) / feedback cycle on threat intelligence (e.g., library vulnerabilities)\n",
    "\n",
    "- embedding it in the SDLC\n",
    "\n",
    "- automatically done in a digital way\n",
    "- tools\n",
    "- version control of threat models\n",
    "- stored where the code is?\n",
    "- linkability: probably done on an application basis, but applications are not isolated\n",
    "- dependency between applications might lead to some applications needing a higher maturity level\n",
    "- write down your decisions\n",
    "- align with the business risk matrix\n",
    "\n",
    "\n",
    "- ownership probably in the development team\n",
    "- someone outside the development environment overviewing interdependencies between threat models\n",
    "\n",
    "- threat intelligence because applications live in a certain moment in time and things change and may make some decisions invalid\n",
    "\n",
    "\n",
    "#### Level 3+\n",
    "\n",
    "- Formalization\n",
    "- list of mitigation strategies\n",
    "- decisions based on continuous learning\n",
    "\n",
    "#### The goal of threat modeling\n",
    "provide input needed by the \"business\" for to make an informed decision on risks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarking\n",
    "\n",
    "One of the key success factors for SAMM is the availability of comparitative data available for the organisations adopting it. One of the challenges is to have a sufficiently open data set that at the same time guarantees anonymity and sufficient quality of data. A potential solution to these challenges was designed in the past. In this session, we want to discuss how to move this forward.\n",
    "\n",
    "tooling and the link with benchmarking\n",
    "will we use the same ways for measuring? will we use new ways?\n",
    "update tool automatically using the data (e.g., .yaml)\n",
    "\n",
    "\n",
    "OWASP resources to build an online application  \n",
    "register and submit\n",
    "\n",
    "\n",
    "if we get to the point where people send too many fake submissions, we'll see what we do about it\n",
    "have a sandbox or playground environment?\n",
    "\n",
    "**collect anonymous data**  \n",
    "address confidenciality an privacy  \n",
    "e.g., store objects like json files that people can see (audit) instead of using a database\n",
    "\n",
    "incentive for people to  \n",
    "- provide their data\n",
    "- compare with other peers\n",
    "\n",
    "collect data   \n",
    "- type of organization\n",
    "- number of people\n",
    "\n",
    "\n",
    "do a survey to collect data  \n",
    "- granularity\n",
    "\n",
    "metadata  \n",
    "- minimum number of data points\n",
    "- region\n",
    "- sector\n",
    "\n",
    "Don't store GDPR-sensitive information\n",
    "\n",
    "contributing sponsors may contribute with data  \n",
    "benchmarking info lists companies; they can opt out  \n",
    "no link between company names and their data  \n",
    "\n",
    "companies can update their data using a key.\n",
    "\n",
    "expiry date for records.\n",
    "\n",
    "the spreadsheet will always exist\n",
    "add submit capabilities.\n",
    "\n",
    "SAMM version support\n",
    "\n",
    "**Incentive oportunity**  \n",
    "when downloading 2.0: if you upload your 1.5 data we help you migrate to 2.0  \n",
    "automated mapping tool (non-open source?)  \n",
    "\n",
    "Show improvement\n",
    "Gamify?\n",
    "\n",
    "if you have your data online and we update the model, we translate the data automatically.\n",
    "\n",
    "Collect data during SAMM training.\n",
    "\n",
    "If you submit data by using the online tool, you should benefit more.\n",
    "\n",
    "Companies can install the tool on-prem.\n",
    "\n",
    "API to provide the datasets?\n",
    "\n",
    "mvp that can be used to collect data to use for benchmarking\n",
    "\n",
    "effort on 3 fronts:\n",
    "- backend\n",
    "- online tool\n",
    "- spreadsheet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agile Guidance\n",
    "\n",
    "### Thursday evening session with rvanderveer\n",
    "\n",
    "Mapping activites to agile\n",
    "Mentioning pitfalls (everything security done by 1 persona, having too many requirements, etc.)\n",
    "\n",
    "The document is ready for review  \n",
    "Feedback\n",
    "- content: john, sebastian a., daniel\n",
    "- end of June\n",
    "- track on GitHub\n",
    "\n",
    "at 30 or 40% of end result\n",
    "\n",
    "Guidance on security champions\n",
    "https://safecode.org/building-secure-software-it-takes-a-champion/\n",
    "\n",
    "we asked for feedback on the impact the quality criteria in the questions can have for agile\n",
    "\n",
    "question writing guidelines  \n",
    "- frequency (in the question, in the criteria)\n",
    "\n",
    "How-to for the toolbox\n",
    "Intro document for release when asking for feedback.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
